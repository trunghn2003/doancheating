import os
from collections import deque
import cv2
import numpy as np

# ============== 1) PHONE DETECTOR: YOLOv8 COCO ==============
from ultralytics import YOLO
yolo = YOLO("yolov8n.pt")  # pretrained COCO

# TÃªn lá»›p 'cell phone' trong COCO (ultralytics Ä‘Ã£ map sáºµn)
PHONE_CLASS_NAME = "cell phone"

# ============== 2) FACE DETECTOR (Ä‘á»ƒ suy ra ROI tai) =========
import mediapipe as mp
mp_face = mp.solutions.face_detection
face_det = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6)

# ============== 3) (TÃ™Y CHá»ŒN) EARPHONE DETECTOR: ROBOFLOW =====
USE_ROBOFLOW = False  # báº­t True náº¿u báº¡n cÃ³ API Key + model
ROBOFLOW_MODEL_ID = "cellphone-0aodn-pyq38/1"   # thay báº±ng model id thá»±c táº¿ trÃªn Roboflow
ROBOFLOW_API_KEY = "Kw3rtMLVahV7lmO48WV1"  # export ROBOFLOW_API_KEY=...
rf_model = None

if USE_ROBOFLOW and ROBOFLOW_API_KEY:
    try:
        from roboflow import Roboflow
        rf = Roboflow(api_key=ROBOFLOW_API_KEY)
        # vÃ­ dá»¥ workspace = 'your-workspace'
        # project = rf.workspace(workspace).project(project_slug)
        # nhÆ°ng tiá»‡n nháº¥t: rf.model(MODEL_ID) náº¿u SDK há»— trá»£ tháº³ng.
        rf_model = rf.model(ROBOFLOW_MODEL_ID)
        print("âœ… Roboflow model loaded.")
    except Exception as e:
        print("âš ï¸ Roboflow init failed:", e)
        rf_model = None

# ============== 4) THAM Sá» & HÃ€M PHá»¤ TRá»¢ =====================

# Smoothing: cáº§n phÃ¡t hiá»‡n liÃªn tiáº¿p N khung má»›i bÃ¡o
N_CONSEC_FRAMES_PHONE = 5
N_CONSEC_FRAMES_EARBUD = 8

phone_queue = deque(maxlen=N_CONSEC_FRAMES_PHONE)
earbud_queue = deque(maxlen=N_CONSEC_FRAMES_EARBUD)

def expand_box(xyxy, img_w, img_h, scale=1.15):
    x1, y1, x2, y2 = xyxy
    cx = (x1 + x2) / 2.0
    cy = (y1 + y2) / 2.0
    w = (x2 - x1) * scale
    h = (y2 - y1) * scale
    nx1 = max(0, int(cx - w/2)); ny1 = max(0, int(cy - h/2))
    nx2 = min(img_w - 1, int(cx + w/2)); ny2 = min(img_h - 1, int(cy + h/2))
    return nx1, ny1, nx2, ny2

def infer_phone_boxes(frame, conf_thres=0.3):
    """Tráº£ vá» list bbox (x1,y1,x2,y2,conf) cho class 'cell phone'."""
    res = yolo(frame, verbose=False)[0]
    boxes = []
    for b in res.boxes:
        cls_id = int(b.cls[0])
        cls_name = res.names[cls_id]
        conf = float(b.conf[0])
        if cls_name == PHONE_CLASS_NAME and conf >= conf_thres:
            x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())
            boxes.append((x1, y1, x2, y2, conf))
    return boxes

def face_to_ear_rois(frame, detections, ear_ratio=0.25, ear_height_ratio=0.45):
    """
    Suy ra ROI tai trÃ¡i/pháº£i tÆ°Æ¡ng Ä‘á»‘i theo bbox máº·t.
    - ear_ratio: bá» rá»™ng vÃ¹ng tai so vá»›i bá» rá»™ng máº·t
    - ear_height_ratio: bá» cao vÃ¹ng tai so vá»›i bá» cao máº·t (á»Ÿ giá»¯a theo trá»¥c dá»c)
    """
    H, W = frame.shape[:2]
    rois = []
    for det in detections:
        # mediapipe tráº£ relative bbox (x,y,w,h) theo tá»· lá»‡
        rel = det.location_data.relative_bounding_box
        fx, fy, fw, fh = rel.xmin, rel.ymin, rel.width, rel.height
        x1 = int(max(0, fx * W)); y1 = int(max(0, fy * H))
        x2 = int(min(W - 1, (fx + fw) * W)); y2 = int(min(H - 1, (fy + fh) * H))
        bw, bh = (x2 - x1), (y2 - y1)

        ear_w = int(bw * ear_ratio)
        ear_h = int(bh * ear_height_ratio)
        ear_y1 = y1 + (bh - ear_h)//2
        ear_y2 = ear_y1 + ear_h

        # Tai trÃ¡i (bÃªn trÃ¡i bbox máº·t)
        left_roi = (max(0, x1 - ear_w), max(0, ear_y1), max(0, x1), min(H - 1, ear_y2))
        # Tai pháº£i (bÃªn pháº£i bbox máº·t)
        right_roi = (min(W - 1, x2), max(0, ear_y1), min(W - 1, x2 + ear_w), min(H - 1, ear_y2))

        rois.append(("left", left_roi))
        rois.append(("right", right_roi))
    return rois

def roboflow_detect_earbud(crop_bgr, conf_thres=0.5):
    """Gá»i Roboflow model trÃªn ROI tai (náº¿u cÃ³). Tráº£ True náº¿u tháº¥y earbud/earphone."""
    if rf_model is None:
        return False, 0.0
    # Roboflow nháº­n file path/np array tÃ¹y SDK version; dÃ¹ng táº¡m qua buffer.
    try:
        # convert BGR->RGB
        crop_rgb = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2RGB)
        # má»™t sá»‘ SDK cáº§n cv2.imwrite ra tá»‡p táº¡m; á»Ÿ Ä‘Ã¢y dÃ¹ng array:
        pred = rf_model.predict(crop_rgb, confidence=conf_thres).json()
        # TÃ¹y model, class name cÃ³ thá»ƒ lÃ  'earbud', 'earphone', 'earpiece'...
        found = False
        best = 0.0
        for p in pred.get("predictions", []):
            cls = p.get("class", "").lower()
            conf = float(p.get("confidence", 0.0))
            if any(k in cls for k in ["earbud", "earphone", "earpiece", "headset"]):
                found = True
                best = max(best, conf)
        return found, best
    except Exception as e:
        # Náº¿u lá»—i API, coi nhÆ° khÃ´ng phÃ¡t hiá»‡n
        # print("RF error:", e)
        return False, 0.0

def draw_box(img, box, color, label=None):
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)
    if label:
        cv2.putText(img, label, (x1, max(0, y1-6)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)

# ============== 5) MAIN LOOP =================================
cap = cv2.VideoCapture(0)  # Ä‘á»•i sang Ä‘Æ°á»ng dáº«n video náº¿u cáº§n
if not cap.isOpened():
    raise SystemExit("Cannot open camera")

print("Press 'q' to quit.")
def main():
    cap = cv2.VideoCapture(0)  # Ä‘á»•i sang Ä‘Æ°á»ng dáº«n video náº¿u cáº§n
while True:
    ret, frame = cap.read()
    if not ret:
        break
    H, W = frame.shape[:2]

    # 1) Phone
    phone_boxes = infer_phone_boxes(frame, conf_thres=0.35)
    phone_present = len(phone_boxes) > 0
    phone_queue.append(1 if phone_present else 0)

    for (x1,y1,x2,y2,conf) in phone_boxes:
        draw_box(frame, (x1,y1,x2,y2), (0,255,255), f"phone {conf:.2f}")

    # 2) Face -> ear ROIs
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    res = face_det.process(rgb)
    ear_present = False
    best_ear_conf = 0.0

    if res.detections:
        ear_rois = face_to_ear_rois(frame, res.detections)
        for side, (ex1,ey1,ex2,ey2) in ear_rois:
            if ex2 <= ex1 or ey2 <= ey1:
                continue
            crop = frame[ey1:ey2, ex1:ex2]
            # 3) (Optional) detect earbud via Roboflow on ear-ROI
            ear_found, ear_conf = roboflow_detect_earbud(crop, conf_thres=0.5)
            if ear_found:
                ear_present = True
                best_ear_conf = max(best_ear_conf, ear_conf)
                draw_box(frame, (ex1,ey1,ex2,ey2), (0,0,255), f"{side} earbud {ear_conf:.2f}")
            else:
                draw_box(frame, (ex1,ey1,ex2,ey2), (200,200,200), f"{side} ear ROI")

    earbud_queue.append(1 if ear_present else 0)

    # 4) Smoothing & Alerts
    phone_alert = (sum(phone_queue) == phone_queue.maxlen)
    ear_alert = (sum(earbud_queue) == earbud_queue.maxlen)

    if phone_alert:
        cv2.putText(frame, "ðŸš¨ PHONE DETECTED (stable)", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 2, cv2.LINE_AA)

    if ear_alert:
        cv2.putText(frame, f"ðŸš¨ EARPHONE DETECTED (stable {best_ear_conf:.2f})", (20, 80),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 2, cv2.LINE_AA)

    cv2.imshow("Exam Monitor POC", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release(); cv2.destroyAllWindows()
    cap.release()
    cv2.destroyAllWindows()

# ============== 6) ADD FACE TO DATABASE (DUMMY) =================
def add_face_to_database(image_path, name):
    """
    HÃ m nÃ y sáº½ táº£i áº£nh tá»« Ä‘Æ°á»ng dáº«n `image_path`,
    trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng khuÃ´n máº·t (sá»­ dá»¥ng thÆ° viá»‡n nhÆ° FaceNet),
    vÃ  lÆ°u trá»¯ vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u cÃ¹ng vá»›i tÃªn ngÆ°á»i dÃ¹ng.
    (ÄÃ¢y chá»‰ lÃ  má»™t vÃ­ dá»¥ Ä‘Æ¡n giáº£n, báº¡n cáº§n thay tháº¿ báº±ng logic thá»±c táº¿)
    """
    print(f"ÄÃ£ thÃªm khuÃ´n máº·t cá»§a {name} tá»« áº£nh {image_path} vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u.")

# ============== 7) MAIN ENTRY POINT ============================
if __name__ == "__main__":
    print("Press 'q' to quit.")
    # VÃ­ dá»¥ sá»­ dá»¥ng hÃ m add_face_to_database (cáº§n thay Ä‘á»•i logic bÃªn trong)
    # add_face_to_database("path/to/your/image.jpg", "Your Name")
    main()
