{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_head_pose(yaw, pitch, roll, YAW_THRESHOLD = 20, PITCH_THRESHOLD = 20, ROLL_THRESHOLD = 20):\n",
    "    \"\"\"\n",
    "    Classifies head pose based on yaw, pitch, and roll angles.\n",
    "\n",
    "    Parameters:\n",
    "    - yaw (float): Horizontal head rotation (left/right).\n",
    "    - pitch (float): Vertical head movement (up/down).\n",
    "    - roll (float): Head tilt (sideways).\n",
    "\n",
    "    Returns:\n",
    "    - String representing the classified head pose.\n",
    "    \"\"\"\n",
    "\n",
    "    # Classify yaw (left/right)\n",
    "    if yaw < -YAW_THRESHOLD:\n",
    "        return \"Looking Down\"\n",
    "    elif yaw > YAW_THRESHOLD:\n",
    "        return \"Looking Up\"\n",
    "\n",
    "    # Classify pitch (up/down)\n",
    "    if pitch > PITCH_THRESHOLD:\n",
    "        return \"Looking Left\"\n",
    "    elif pitch < -PITCH_THRESHOLD:\n",
    "        return \"Looking Right\"\n",
    "\n",
    "    # Classify roll (head tilting)\n",
    "    if roll > ROLL_THRESHOLD:\n",
    "        return \"Tilting Left\"\n",
    "    elif roll < -ROLL_THRESHOLD:\n",
    "        return \"Tilting Right\"\n",
    "\n",
    "    # Default case: looking straight\n",
    "    return \"Straight\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.23.1-cp313-cp313-macosx_13_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/anaconda3/lib/python3.13/site-packages (from onnxruntime) (2.1.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.13/site-packages (from onnxruntime) (5.29.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.13/site-packages (from onnxruntime) (1.13.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.23.1-cp313-cp313-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [onnxruntime][0m \u001b[32m3/4\u001b[0m [onnxruntime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 onnxruntime-1.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/hoangtrung/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/hoangtrung/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/hoangtrung/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/hoangtrung/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/hoangtrung/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Straight\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "import cv2\n",
    "\n",
    "# Load the face detection model\n",
    "detector = insightface.app.FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "detector.prepare(ctx_id=0)\n",
    "\n",
    "# Read an image\n",
    "img = cv2.imread(\"faceset/image.jpg\")\n",
    "faces = detector.get(img)\n",
    "# Get the largest detected face (assuming main subject)\n",
    "face = max(faces, key=lambda f: f.bbox[2] - f.bbox[0])\n",
    "\n",
    "# Extract pose values (yaw, pitch, roll)\n",
    "yaw, pitch, roll = face.pose\n",
    "\n",
    "# Classify head pose\n",
    "predicted_class = classify_head_pose(yaw, pitch, roll)\n",
    "\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: insightface in /opt/anaconda3/lib/python3.13/site-packages (0.7.3)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (1.15.3)\n",
      "Requirement already satisfied: onnx in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (1.19.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (2.32.3)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (11.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (1.6.1)\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (0.25.0)\n",
      "Requirement already satisfied: easydict in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (1.13)\n",
      "Requirement already satisfied: cython in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (3.1.4)\n",
      "Requirement already satisfied: albumentations in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (2.0.8)\n",
      "Requirement already satisfied: prettytable in /opt/anaconda3/lib/python3.13/site-packages (from insightface) (3.16.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.13/site-packages (from albumentations->insightface) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /opt/anaconda3/lib/python3.13/site-packages (from albumentations->insightface) (2.10.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /opt/anaconda3/lib/python3.13/site-packages (from albumentations->insightface) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/anaconda3/lib/python3.13/site-packages (from albumentations->insightface) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /opt/anaconda3/lib/python3.13/site-packages (from albucore==0.0.24->albumentations->insightface) (4.2.1)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /opt/anaconda3/lib/python3.13/site-packages (from albucore==0.0.24->albumentations->insightface) (6.5.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations->insightface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations->insightface) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /opt/anaconda3/lib/python3.13/site-packages (from onnx->insightface) (5.29.3)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from onnx->insightface) (0.5.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.13/site-packages (from prettytable->insightface) (0.2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->insightface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->insightface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->insightface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->insightface) (2025.10.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-image->insightface) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-image->insightface) (2025.2.18)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-image->insightface) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->insightface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->insightface) (3.5.0)\n",
      "Downloading torch-2.8.0-cp313-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m781.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m802.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchvision][0m \u001b[32m1/2\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch-2.8.0 torchvision-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "  insightface \\\n",
    "  torch \\\n",
    "  torchvision \\\n",
    "  numpy \\\n",
    "  matplotlib \\\n",
    "  tqdm \\\n",
    "  scipy \\\n",
    "#   bcolz \\\n",
    "  easydict \\\n",
    "  opencv-python \\\n",
    "  Pillow \\\n",
    "  scikit-learn \\\n",
    "  tensorboardX \\\n",
    "  mxnet\n",
    "# Nếu có CUDA 9.0 thì thay dòng mxnet ở trên bằng:\n",
    "#   mxnet-cu90==1.2.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "def test_with_camera():\n",
    "    # Initialize webcam with reduced resolution\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Set width to 640\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Set height to 480\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)  # Target 30 FPS (if supported)\n",
    "\n",
    "    # Frame skipping parameters\n",
    "    process_every_n_frames = 2  # Process every 2nd frame\n",
    "    frame_count = 0\n",
    "\n",
    "    # Queue for thread-safe face detection results\n",
    "    result_queue = queue.Queue()\n",
    "    last_face = None\n",
    "\n",
    "    def face_detection_thread(frame_queue, result_queue):\n",
    "        while True:\n",
    "            try:\n",
    "                rgb_frame = frame_queue.get(timeout=1)\n",
    "                # Detect faces\n",
    "                faces = detector.get(rgb_frame)\n",
    "                result_queue.put(faces if faces else None)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "    # Start face detection in a separate thread\n",
    "    frame_queue = queue.Queue(maxsize=1)\n",
    "    detection_thread = threading.Thread(target=face_detection_thread, args=(frame_queue, result_queue), daemon=True)\n",
    "    detection_thread.start()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        # Resize frame for display (optional, if lower resolution is desired for display)\n",
    "        display_frame = frame  # Can resize further: cv2.resize(frame, (320, 240))\n",
    "\n",
    "        # Process every nth frame for face detection\n",
    "        if frame_count % process_every_n_frames == 0:\n",
    "            # Convert BGR to RGB for face detection\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Optionally downscale for faster detection\n",
    "            small_rgb_frame = cv2.resize(rgb_frame, (320, 240))\n",
    "            \n",
    "            # Put frame in queue for detection\n",
    "            if frame_queue.empty():\n",
    "                frame_queue.put(small_rgb_frame)\n",
    "\n",
    "        # Check for detection results\n",
    "        try:\n",
    "            faces = result_queue.get_nowait()\n",
    "            if faces:\n",
    "                last_face = max(faces, key=lambda f: f.bbox[2] - f.bbox[0])\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "\n",
    "        # Use the last detected face (if available)\n",
    "        if last_face:\n",
    "            # Scale bounding box back to original frame size (if resized)\n",
    "            scale_x, scale_y = frame.shape[1] / 320, frame.shape[0] / 240\n",
    "            x1, y1, x2, y2 = map(int, [last_face.bbox[0] * scale_x, last_face.bbox[1] * scale_y,\n",
    "                                       last_face.bbox[2] * scale_x, last_face.bbox[3] * scale_y])\n",
    "            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Extract and classify pose\n",
    "            yaw, pitch, roll = last_face.pose\n",
    "            predicted_class = classify_head_pose(yaw, pitch, roll)\n",
    "\n",
    "            # Display pose and classification (update less frequently to save time)\n",
    "            if frame_count % process_every_n_frames == 0:\n",
    "                cv2.putText(display_frame, f\"Yaw: {yaw:.2f}, Pitch: {pitch:.2f}, Roll: {roll:.2f}\",\n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(display_frame, f\"Pose: {predicted_class}\",\n",
    "                            (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('Real-time Head Pose Classification', display_frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    test_with_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (face_detection_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.19/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/hoangtrung/Documents/doancheating/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.19/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/tn/l4vhfvtd4tj07xtfn85qhgm00000gn/T/ipykernel_48753/189718314.py\", line 26, in face_detection_thread\n",
      "NameError: name 'detector' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Run webcam test\n",
    "test_with_camera()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
